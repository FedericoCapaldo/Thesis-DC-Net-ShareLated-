\chapter{Evaluation}
This chapter contains a personal reflection on the implemented protocol. 

CAMBIA: to present its strength, to assess its contribution to academia,  and weaknesses, to identify possible areas of improvement. 

\section{Assessment on the implementation against the requirements}
The simulation implemented met all the basic requirements and advanced requirements outlined in section \ref{sec:requirements}. Not only the simulation performs the core multi-party XOR computation of three entities, but it also acknowledges several limitations proposing solutions to each one:
\begin{itemize}
    \item message collisions are detected;
    \item the communication occurs in different types of rounds (voting, length calculation and communication) so as to send longer messages;
    \item I adopt EASCII encoding to translate the result of communication rounds into letters so as to communicate human-readable messages;
    \item any number of participants can join or leave the network during the protocol execution without affecting the correctness of the messages exchanged;
\end{itemize}
All of the above takes place with an actual distributed architecture and using a graphical user interface.

I, therefore, consider this a satisfactory implementation.


\section{Comparison of simulation with other works}
Relative to the other implementations found online, my simulation tool implemented proposes some additions that the improve the state of the art of Dining Cryptographer simulated implementations. The main contributions are:
\begin{enumerate}
    \item \textbf{User-experience:} while current tools generally present difficult installation, I provide an easier user experience readily available online. Moreover, the user interface is improved. Current tools mostly offer a command-line interface, which requires the user to \textit{memorise} verbose commands. The user experience provided is, instead, more intuitive with the use of a GUI, which only requires to \textit{recognize} visual cues like buttons and colors. Plus, the simulation is equipped with a number of descriptive messages about what is happening during the execution of the protocol;
    \item \textbf{Documentation}: Tools found provide incomplete or unusable documentation, which may be especially important in understanding a command-line software. The implementation achieved has no remarkable learning barrier but, if needed, a visual user guide is provided (see Appendix \ref{appendix:userGuide});
    \item \textbf{Distributed architecture}: all tools found run locally on a single machine. The simulation implemented offers a realistic experience through the website, since it allows users to connect to the server from different physical locations.
\end{enumerate}

On the whole, this number of improvements move the current state of art forward and enables cryptography enthusiasts learn in a practical way the potential of this protocol.

\section{Known limitations of the implemented solution}
\noindent Despite the improvements, there is a number of known limitations to be acknowledged. 

\subsection{Key Exchange}
As the software has been developed as a web application, \lstinline{https} protocol is the standard way to encrypt traffic over the Internet. \lstinline{Https} provides a solution to exchange keys securely, however, it does not address the problem of key exchange at a protocol level. Such omission is possible because the implementation assumes the channel of communication is the Internet. Therefore, the key-exchange process, at the current state, is not secure within the codebase.

All in all, a more refined solution would settle the key-exchange issue at a protocol level with public key cryptography, such as Diffie-Hellman, or synchronized cryptographically secure pseudo-random number generators (see section \ref{sec:keyExchangeMethods}). This would ensure that, even if this simulation were not web-based, the key-exchange procedure would be secure. However, time constraints played a role in which features I could implement.

\subsection{Collusion}
A real-world scenario that I do not address in this simulation is the possible collusion of malicious participants inside the network. Indeed, attackers could join forces and pool their keys together in order to reveal who the real sender is, as explained in section \ref{sec:disruptionlimitation}. A system that also addresses this issue needs complex mechanisms such as a tree-like overlay network \cite{Wang}, that are beyond the scope of this project.

\subsection{Presence of Server} \label{sec:evalServerPresence}
Making use of a client-server architecture introduces the entity of the server, which represents the DC-Net Service. This raises the issue of trust and it calls for an assumption that, at server level, there is no abuse of the comprehensive view of the network (see section \ref{sec:clientserver}). Since this is a web application, the use of a SSL certificate would verify the server's identify but a client using this platform cannot know how the server handles the responses sent to it. I made a design choice between the useful but questionable presence of an omniscient principal, the server, and the choice of a serverless architecture but with limited capabilities. The client-server architecture was chosen because the presence of a centralised service allows the implementation of some advanced features. For example, it would not be possible to detect collisions without an entity that is able to see all the messages in a round.

\subsection{Collision Detection Warnings: Effects}
In my implementation, I divided communication in three types of round (voting, length-calculation, communication rounds) as presented in section \ref{sec:advancedReq}.
As presented in \ref{sec:collisionDetectionWarnings}, a collision detection warning is sent solely to the failing participants who attempted to win a voting round. Although I justify the necessity of such mechanism, I came to realise that there are implications in respect to untraceability, which cannot be overlooked.


\subsubsection{Anonymity Reduction} \label{sec:anonymityReductionLimitation}
Anonymity, as we have seen, is not an absolute concept; rather, it depends on the number of participants inside the anonymity set (section \ref{sec:anonymityset}), 

During a critical review of the features implemented, I found out that 'rejection warning' notifications reduce the sender anonymity set because an eavesdropper can deduct that none of the clients who received such notification is the potential real sender. It follows that the anonymity set is reduced to those participants not receiving such warning notification. As a result, sender anonymity is reduced.

The reality is that there is no easy workaround to maintain the degree of anonymity unaffected. Hypothetically, if the user experience would be sidelined, the server could simply drop the unsuccessful attempts to win the voting round and not send a rejection warning message back. However, there must still be an update of state of the client's browser to change their sender status so that there is no prompt to send a message, and this can come only from the server.

\subsubsection{Edge case of anonymity impairment} \label{sec:anonymityImpairmentEdgeCase}
I also found an edge case, where an eavesdropper inside the network can impair the internal untraceability of a round due to the same 'rejection warning' notifications. The edge case scenario consists of three cryptographers with the following features: 

\begin{enumerate}
    \item a message sender who won the voting round;
    \item a second participant that tried to win the voting round;
    \item a third participant, eavesdropping, who can listen in to all communication from and to the server.
\end{enumerate}
It follows that, since there are only two participants other than the eavesdropper, then the eavesdropper knows that the message sender obviously is the client who did not receive a rejection. In this case, anonymity is internally breached and only 'preserved' in respect to an external observer, assuming that such observer is not colluding with the internal eavesdropper.


\section{Discrepancy between Theoretical Protocol and Real World Implementation} \label{sec:collisionDetect}
With this implementation, I want to highlight the gap between the theoretical perfection of the Dining Cryptographers protocol and the weaknesses of a functional solution deployed. The discrepancy stands in the challenge of preserving the desired security properties and maintaining correctness of the protocol. 

The effort of putting a theoretical protocol in practice, overcoming complications that arose during each step of development, has triggered a series of reflections. The rest of the chapter gives space to considerable practical challenges, too often neglected in the theoretical literature.

\subsection{Correctness of protocol execution}
The protocol in theory is presented by Chaum with cryptographers at the table. In an actual implementation, there is the process of sitting down at the table. In other words, there is a connection event for each client to the DC-Net Service, and therefore a temporal element in joining the network, which may take place at different phases of the protocol execution. Such element can, in practise, create an issue of correctness when one or more participants join or leave the protocol during the actual execution.

\subsubsection{Correctness of protocol on client connection during protocol execution}
Adding a participant to the graph implies updating the adjacencies of the graph, i.e. renewing the secret keys between clients. If a connection of a $nth$ client happens when the protocol started and some, but not all, participants already provided their responses, then, performing an update of adjacencies at this stage would create a mismatch of state between the clients and the server.

More specifically, after the keys updated, the combination of old responses recorder by the server in conjunction with the missing responses of that will now be provided to the server will not XOR each other out, therefore affecting the correctness of the protocol.

Thus, the simulations employs a waiting mechanism for clients that join the network in the midst of the protocol execution to delay their participation until the next voting round.

\subsubsection{Correctness of protocol on client disconnections}
Another important problem not addressed by theoretical works is the event of disconnection of a user while the protocol is executing. A client abandoning the network after the key-exchange phase in either of the voting, length-calculation, or communication rounds undermines the correctness of the final result because the response of the disconnecting client is excluded in the server's final round calculation. This leads to an incorrect round results since some of the secret keys are not XORed twice, which is fundamental to reveal the broadcasted hidden round message (a EASCII character) sent by the anonymous message sender (see section \ref{sec:xorDemonstration}).

The immediate solution is to, again, update the adjacencies when a client disconnects and, if necessary, stop and restart the round. However, in a network with $n$ number of participants, such mechanism would affect the user experience and serviceability of the protocol. Moreover, it also allows a malicious participant to harm the availability of the service by simply connecting and disconnecting to the service repeatedly.

It is in these circumstances that the presence of the DC-Net service is valuable. That is, when a disconnection occurs, the server that keeps track of all of the adjacencies' keys, simply updates the two relevant adjacency objects and their respective keys, without interrupting the round in progress.

\subsection{Edge cases that compromise untraceability}
The protocol in principle describes the minimum set of communication steps necessary for a smooth round of communication. However, in a real world scenario, it is very likely that more messages or events are exchanged between a client and the server. For instance, a relevant case is the 'collision detection warning' notification, (section \ref{sec:collisionDetectionWarnings}), which affects the degree of untraceability, by reducing the sender anonymity set. 

Although I presented this example in the known limitations of my simulator, this complication is very likely to be encountered in any attempt of implementing this protocol. The more complex an implementation is, the higher the likelihood of compromising untraceability by introducing new communication steps. Therefore, guaranteeing untraceability for all edge cases in practical implementations is more laborious than ensuring the perfection of the cryptographic algorithm at a theoretical level. 


\subsection{Necessity of a length-calculation round}
A proposal to extend the protocol to multiple rounds of communications is offered by many academic figures. This divides communication in a voting phase and a actual sending phase.

Although this approach is the same proposed for my implementation, I identified the necessity of a third type of round was identified: length-calculation round. This leads to a division of the protocol execution in voting, length-calculation and communication rounds. The newly introduced round type has the purpose of allowing the message sender to communicate the length of the sentence to the server without being traced by potential eavesdroppers. I deemed this step necessary, since in my implementation the server needs to compute the same number of keys as the length of the sentence before the communication rounds start. Without this intermediate round type, a message sender that will directly communicate the length of the message to the server would be trivially identified by an eavesdropper.

The need of this step was never found in the theoretical works that simply propose to divide the protocol in voting and communication rounds.


\subsection{Difficulty of ensuring fair use of network}
DC-Net protocol focuses on untraceability. When looking at the implementation of a software, however, another main security goal to be guaranteed is availability. In the context of the implemented simulation, a malicious participant could decide to hog the service and make it unavailable by continuously attempting to win the voting round. To counteract this issue, I implement a feature that prevents the message sender to win the next voting round. By doing so, a malicious participant trying to hog the service, can succeed only half of the time (one round yes and one round no).

However, the ideal solution to ensure fairness in the network usage is to implement a queue. The server would make use of this data structure to record the chronological order of attempts by the participants to send a message. This allows a participant to send a message when he reaches the front of the queue. Nonetheless, this is a very fiddly feature to implement due to intricate possible scenarios. 


An example of how complicated this quickly becomes is the following. There are at least two cryptographers in the sending queue who tried to win the voting round simultaneously. At the start of the new round the user at the front of the queue is asked if he would still like to send a message. The first issue raised is that this question cannot be a unicast message between the client and the server. Otherwise if after this communication the length-calculation round happens, it would be obvious who the sender is. Therefore, to maintain untraceability this question would require a further type of broadcast round. 

Furthermore, there are particular edge cases to be addressed. For example, what happens if the cryptographer, front of the queue, accepted to send a message but then disconnects? It is likely that that the same offer of sending a message should be made to the new first user in the queue, having to repeat another broadcast round just to ask this. Hence, implementing a queue of message senders risks to make the protocol to repeat the voting phase several times. This is the completely counterproductive since it could affect the availability of the service ,which was the issue that the queue set out to solve in the first place. 

This is an excellent instance of how an implementation can get highly difficult rather quickly. \newline \newline




Ultimately, all these various exemplifications of differences between a theoretical protocol and an effective application illustrated the constructive knowledge gained along the hands-on development phase. The purely theoretical argumentation of the protocol presented in many papers rarely offer an appreciation of these practical complex challenges. Hence, these were important remarks to be addressed as a contribution to the academic community.

